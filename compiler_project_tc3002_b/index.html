<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Lexical Analyzer"><title>compiler_project_tc3002_b - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../static.files/rustdoc-6c3ea77c.css"><meta name="rustdoc-vars" data-root-path="../" data-static-root-path="../static.files/" data-current-crate="compiler_project_tc3002_b" data-themes="" data-resource-suffix="" data-rustdoc-version="1.86.0 (05f9846f8 2025-03-31)" data-channel="1.86.0" data-search-js="search-581efc7a.js" data-settings-js="settings-6dad6058.js" ><script src="../static.files/storage-3a5871a4.js"></script><script defer src="../crates.js"></script><script defer src="../static.files/main-4d63596a.js"></script><noscript><link rel="stylesheet" href="../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../static.files/favicon-044be391.svg"></head><body class="rustdoc mod crate"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../compiler_project_tc3002_b/index.html">compiler_<wbr>project_<wbr>tc3002_<wbr>b</a><span class="version">0.1.0</span></h2></div><div class="sidebar-elems"><ul class="block"><li><a id="all-types" href="all.html">All Items</a></li></ul><section id="rustdoc-toc"><h3><a href="#">Sections</a></h3><ul class="block top-toc"><li><a href="#lexical-analyzer" title="Lexical Analyzer">Lexical Analyzer</a><ul><li><a href="#diego-eduardo-hernandez-cadena---a00834015" title="Diego Eduardo Hernandez Cadena - A00834015">Diego Eduardo Hernandez Cadena - A00834015</a></li><li><a href="#usage" title="Usage">Usage</a></li><li><a href="#adding-more-keywords-and-operators" title="Adding more keywords and operators">Adding more keywords and operators</a></li><li><a href="#adding-more-tokens" title="Adding more tokens">Adding more tokens</a></li></ul></li></ul><h3><a href="#enums">Crate Items</a></h3><ul class="block"><li><a href="#enums" title="Enums">Enums</a></li><li><a href="#functions" title="Functions">Functions</a></li></ul></section><div id="rustdoc-modnav"></div></div></nav><div class="sidebar-resizer"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1>Crate <span>compiler_project_tc3002_b</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../src/compiler_project_tc3002_b/lib.rs.html#1-209">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><h2 id="lexical-analyzer"><a class="doc-anchor" href="#lexical-analyzer">§</a>Lexical Analyzer</h2><h5 id="diego-eduardo-hernandez-cadena---a00834015"><a class="doc-anchor" href="#diego-eduardo-hernandez-cadena---a00834015">§</a>Diego Eduardo Hernandez Cadena - A00834015</h5>
<p>Implements a lexical analyzer using the <code>plex</code> crate. It reads the specified input file, tries to parse it, and prints a list of the resulting tokens.</p>
<h3 id="usage"><a class="doc-anchor" href="#usage">§</a>Usage</h3>
<p>To use the lexical analyzer, set the <code>INPUT_FILE_PATH</code> constant to the desired location and run <code>cargo run</code> to execute the program.</p>
<h3 id="adding-more-keywords-and-operators"><a class="doc-anchor" href="#adding-more-keywords-and-operators">§</a>Adding more keywords and operators</h3>
<p>To add a keyword or operator:</p>
<ul>
<li>Add it to the <code>Keyword</code> or <code>Operator</code> enum.</li>
<li>Add an entry to the corresponding <code>phf_map!</code> static map.</li>
<li>If necessary, update the regular expressions in the <code>lexer!</code> macro.</li>
</ul>
<h3 id="adding-more-tokens"><a class="doc-anchor" href="#adding-more-tokens">§</a>Adding more tokens</h3>
<p>To add a new token:</p>
<ul>
<li>Add a new variant to the <code>Token</code> enum.</li>
<li>Add a matching rule in the <code>lexer!</code> macro that maps input to the new token.</li>
</ul>
</div></details><h2 id="enums" class="section-header">Enums<a href="#enums" class="anchor">§</a></h2><dl class="item-table"><dt><a class="enum" href="enum.Keyword.html" title="enum compiler_project_tc3002_b::Keyword">Keyword</a></dt><dd>Represents supported keywords that the lexer can recognize</dd><dt><a class="enum" href="enum.Operator.html" title="enum compiler_project_tc3002_b::Operator">Operator</a></dt><dd>Represents supported operators in the language</dd><dt><a class="enum" href="enum.Token.html" title="enum compiler_project_tc3002_b::Token">Token</a></dt><dd>Represents all possible tokens that can be produced by the lexer</dd></dl><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">§</a></h2><dl class="item-table"><dt><a class="fn" href="fn.extract_file_contents.html" title="fn compiler_project_tc3002_b::extract_file_contents">extract_<wbr>file_<wbr>contents</a></dt><dd>Reads the contents of the file at the specified path</dd><dt><a class="fn" href="fn.extract_tokens.html" title="fn compiler_project_tc3002_b::extract_tokens">extract_<wbr>tokens</a></dt><dd>Extracts all tokens from the input string using the lexer</dd><dt><a class="fn" href="fn.parse_keyword.html" title="fn compiler_project_tc3002_b::parse_keyword">parse_<wbr>keyword</a></dt><dd>Tries to match a string slice to a known <code>Keyword</code></dd><dt><a class="fn" href="fn.parse_operator.html" title="fn compiler_project_tc3002_b::parse_operator">parse_<wbr>operator</a></dt><dd>Tries to match a string slice to a known <code>Operator</code></dd><dt><a class="fn" href="fn.run.html" title="fn compiler_project_tc3002_b::run">run</a></dt><dd>Main function: reads input, tokenizes it, and prints each token (excluding whitespace)</dd></dl></section></div></main></body></html>